{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring Data Science Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we'll be discussing how to refactor code from data science projects to make them more robust, maintainable and scalable. \n",
    "Many data scientists today are trained in mathematics includin probability and statistics as well as other disciplines, however, not all data scientists have training as software engineers. Because of this lack of familiarity with proper software engineering principles,  Code in many data science projects is often underperformant, as well as difficult to maintain and scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar, we will look at a simple data science project that trains a neural network on image recognition.  It will use a very common training set called *MNIST*.  MNIST is a set of gray scale hand drawn numbers.  The purpose of the project is to accurately distinguish different numbers from the images.  The challenge comes from the fact that many of the numbers in the images can be ambiguous.  A \"1\" may look like a \"7\", or a \"5\" may look like a \"6\".   The goal of the project is to look at the data set and accurately predict what is the correct number being displayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by taking a look at the project code.  Our first file is main.py.  \n",
    "main.py starts by importing required libraries.\n",
    "\n",
    "It then sets the neural networks hyperparameters.\n",
    "Next it loads the testing and training data and decides which machine learning model to use. \n",
    "It sets a number of other parameters including the optimization function and the loss function.\n",
    "\n",
    "The code then runs the training and testing epochs for the model.\n",
    "It then calculates the training metrics and then at the end, it resets the project.\n",
    "This project also uses tensorboard to monitor the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.dataset import get_train_dataloader, get_test_dataloader\n",
    "from src.metrics import Metric\n",
    "from src.models import LinearNet\n",
    "from src.tracking import TensorboardExperiment, Stage\n",
    "from src.utils import generate_tensorboard_experiment_directory\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    'EPOCHS': 20,\n",
    "    'LR': 5e-5,\n",
    "    'OPTIMIZER': 'Adam',\n",
    "    'BATCH_SIZE': 128\n",
    "}\n",
    "\n",
    "# Data\n",
    "train_loader = get_train_dataloader(batch_size=hparams.get('BATCH_SIZE'))\n",
    "test_loader = get_test_dataloader(batch_size=hparams.get('BATCH_SIZE'))\n",
    "\n",
    "# Model and Optimizer\n",
    "model = LinearNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams.get('LR'))\n",
    "\n",
    "# Objective (loss) function\n",
    "compute_loss = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Metric Containers\n",
    "train_accuracy = Metric()\n",
    "test_accuracy = Metric()\n",
    "y_true_batches = []\n",
    "y_pred_batches = []\n",
    "\n",
    "# Experiment Trackers\n",
    "log_dir = generate_tensorboard_experiment_directory(root='./runs')\n",
    "experiment = TensorboardExperiment(log_dir=log_dir)\n",
    "\n",
    "# Batch Counters\n",
    "test_batch = 0\n",
    "train_batch = 0\n",
    "\n",
    "for epoch in range(hparams.get('EPOCHS')):\n",
    "    # Testing Loop\n",
    "    for x_test, y_test in tqdm(test_loader, desc='Validation Batches', ncols=80):\n",
    "        test_batch += 1\n",
    "        test_batch_size = x_test.shape[0]\n",
    "        test_pred = model(x_test)\n",
    "        loss = compute_loss(test_pred, y_test)\n",
    "\n",
    "        # Compute Batch Validation Metrics\n",
    "        y_test_np = y_test.detach().numpy()\n",
    "        y_test_pred_np = np.argmax(test_pred.detach().numpy(), axis=1)\n",
    "        batch_test_accuracy = accuracy_score(y_test_np, y_test_pred_np)\n",
    "        test_accuracy.update(batch_test_accuracy, test_batch_size)\n",
    "        experiment.set_stage(Stage.VAL)\n",
    "        experiment.add_batch_metric('accuracy', batch_test_accuracy, test_batch)\n",
    "        y_true_batches += [y_test_np]\n",
    "        y_pred_batches += [y_test_pred_np]\n",
    "\n",
    "    # Training Loop\n",
    "    for x_train, y_train in tqdm(train_loader, desc='Train Batches', ncols=80):\n",
    "        train_batch += 1\n",
    "        train_batch_size = x_train.shape[0]\n",
    "        train_pred = model(x_train)\n",
    "        loss = compute_loss(train_pred, y_train)\n",
    "\n",
    "        # Compute Batch Training Metrics\n",
    "        y_train_np = y_train.detach().numpy()\n",
    "        y_train_pred_np = np.argmax(train_pred.detach().numpy(), axis=1)\n",
    "        batch_train_accuracy = accuracy_score(y_train_np, y_train_pred_np)\n",
    "        train_accuracy.update(batch_train_accuracy, train_batch_size)\n",
    "        experiment.set_stage(Stage.TRAIN)\n",
    "        experiment.add_batch_metric('accuracy', batch_train_accuracy, train_batch)\n",
    "\n",
    "        # Reverse-mode AutoDiff (backpropagation)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute Average Epoch Metrics\n",
    "    summary = ', '.join([\n",
    "        f\"[Epoch: {epoch + 1}/{hparams.get('EPOCHS')}]\",\n",
    "        f\"Test Accuracy: {test_accuracy.average: 0.4f}\",\n",
    "        f\"Train Accuracy: {train_accuracy.average: 0.4f}\",\n",
    "    ])\n",
    "    print('\\n' + summary + '\\n')\n",
    "\n",
    "    # Log Validation Epoch Metrics\n",
    "    experiment.set_stage(Stage.VAL)\n",
    "    experiment.add_epoch_metric('accuracy', test_accuracy.average, epoch)\n",
    "    experiment.add_epoch_confusion_matrix(y_true_batches, y_pred_batches, epoch)\n",
    "\n",
    "    # Log Validation Epoch Metrics\n",
    "    experiment.set_stage(Stage.TRAIN)\n",
    "    experiment.add_epoch_metric('accuracy', train_accuracy.average, epoch)\n",
    "\n",
    "    # Reset metrics\n",
    "    train_accuracy.reset()\n",
    "    test_accuracy.reset()\n",
    "\n",
    "experiment.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code, other than the main.py file, is located in a src folder.  Let's start looking at these modules. \n",
    "The first module we'll examine is dataset.py.\n",
    "\n",
    "This module handles loading the MNIST data set into memory.  IT also has some preprocessing methods to normalize the data for use with the training model. Note that the preprocessing_x method uses a variable (self.x) to store intermediate results.  This is problematic from a proper softwware engineering standpoint.  This is because self.x isn't going to have the same value at different stages during the program execution.   This is an example of a method that needs refactoring. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from src.load_data import load_train_labels, load_train_data, load_test_data, load_test_labels\n",
    "\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    idx: int  # requested data index\n",
    "    x: torch.Tensor\n",
    "    y: torch.Tensor\n",
    "\n",
    "    TRAIN_MAX = 255.0\n",
    "    TRAIN_NORMALIZED_MEAN = 0.1306604762738429\n",
    "    TRAIN_NORMALIZED_STDEV = 0.3081078038564622\n",
    "\n",
    "    def __init__(self, data: np.ndarray, targets: np.ndarray):\n",
    "        if len(data) != len(targets):\n",
    "            raise ValueError('data and targets must be the same length. '\n",
    "                             f'{len(data)} != {len(targets)}')\n",
    "\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.get_x(idx)\n",
    "        y = self.get_y(idx)\n",
    "        return x, y\n",
    "\n",
    "    def get_x(self, idx: int):\n",
    "        self.idx = idx\n",
    "        self.preprocess_x()\n",
    "        return self.x\n",
    "\n",
    "    def preprocess_x(self):\n",
    "        self.x = self.data[self.idx].copy().astype(np.float64)\n",
    "        self.x /= self.TRAIN_MAX\n",
    "        self.x -= self.TRAIN_NORMALIZED_MEAN\n",
    "        self.x /= self.TRAIN_NORMALIZED_STDEV\n",
    "        self.x = self.x.astype(np.float32)\n",
    "        self.x = torch.from_numpy(self.x)\n",
    "        self.x = self.x.unsqueeze(0)\n",
    "\n",
    "    def get_y(self, idx: int):\n",
    "        self.idx = idx\n",
    "        self.preprocess_y()\n",
    "        return self.y\n",
    "\n",
    "    def preprocess_y(self):\n",
    "        self.y = self.targets[self.idx]\n",
    "        self.y = torch.tensor(self.y, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_train_dataloader(batch_size: int) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        dataset=MNIST(load_train_data(), load_train_labels()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_test_dataloader(batch_size: int) -> DataLoader:\n",
    "    return DataLoader(\n",
    "        dataset=MNIST(load_test_data(), load_test_labels()),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the load_data.py module.  This is the low level module that actually handles loading the data directly from the disk. This module reads the data from the disk, make sure that the data is in unsigned byte format, checks the size and dimensions of the data and returns an np.array of both the data and the labels.  Note here that the load_test_data() and load_train_data() methods are nearly identical.  This is a target for refactoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = (Path(__file__).parent / \"../data\").resolve()\n",
    "\n",
    "ALLOWED_TYPES = {\n",
    "    \"UNSIGNED_BYTE\": b\"\\x08\",\n",
    "    \"SIGNED_BYTE\": b\"\\x09\",\n",
    "    \"SHORT\": b\"\\x0B\",\n",
    "    \"INT\": b\"\\x0C\",\n",
    "    \"SINGLE\": b\"\\x0D\",\n",
    "    \"DOUBLE\": b\"\\x0E\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    with gzip.open(DATA_DIR / \"t10k-images-idx3-ubyte.gz\", \"rb\") as fp:\n",
    "        _ = struct.unpack(\">H\", fp.read(2))  # dump padding bytes\n",
    "\n",
    "        (data_type,) = struct.unpack(\">c\", fp.read(1))\n",
    "        assert data_type == ALLOWED_TYPES[\"UNSIGNED_BYTE\"]\n",
    "\n",
    "        number_of_dimensions = ord(struct.unpack(\">c\", fp.read(1))[0])\n",
    "        assert number_of_dimensions == 3\n",
    "\n",
    "        (num_images,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_images == 10_000\n",
    "\n",
    "        (num_rows,) = struct.unpack(\">I\", fp.read(4))\n",
    "        (num_cols,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_rows == num_cols == 28\n",
    "\n",
    "        raw = fp.read()\n",
    "        assert len(raw) == num_images * num_rows * num_cols\n",
    "\n",
    "    data = np.frombuffer(raw, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "    data = data.reshape((num_images, num_rows, num_cols))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_train_data():\n",
    "    with gzip.open(DATA_DIR / \"train-images-idx3-ubyte.gz\", \"rb\") as fp:\n",
    "        _ = struct.unpack(\">H\", fp.read(2))  # dump padding bytes\n",
    "\n",
    "        (data_type,) = struct.unpack(\">c\", fp.read(1))\n",
    "        assert data_type == ALLOWED_TYPES[\"UNSIGNED_BYTE\"]\n",
    "\n",
    "        number_of_dimensions = ord(struct.unpack(\">c\", fp.read(1))[0])\n",
    "        assert number_of_dimensions == 3\n",
    "\n",
    "        (num_images,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_images == 60_000\n",
    "\n",
    "        (num_rows,) = struct.unpack(\">I\", fp.read(4))\n",
    "        (num_cols,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_rows == num_cols == 28\n",
    "\n",
    "        raw = fp.read()\n",
    "        assert len(raw) == num_images * num_rows * num_cols\n",
    "\n",
    "    data = np.frombuffer(raw, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "    data = data.reshape((num_images, num_rows, num_cols))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_test_labels():\n",
    "    with gzip.open(DATA_DIR / \"t10k-labels-idx1-ubyte.gz\", \"rb\") as fp:\n",
    "        _ = struct.unpack(\">H\", fp.read(2))  # dump padding bytes\n",
    "\n",
    "        (data_type,) = struct.unpack(\">c\", fp.read(1))\n",
    "        assert data_type == ALLOWED_TYPES[\"UNSIGNED_BYTE\"]\n",
    "\n",
    "        number_of_dimensions = ord(struct.unpack(\">c\", fp.read(1))[0])\n",
    "        assert number_of_dimensions == 1\n",
    "\n",
    "        (num_images,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_images == 10_000\n",
    "\n",
    "        raw = fp.read()\n",
    "        assert len(raw) == num_images\n",
    "\n",
    "    data = np.frombuffer(raw, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_train_labels():\n",
    "    with gzip.open(DATA_DIR / \"train-labels-idx1-ubyte.gz\", \"rb\") as fp:\n",
    "        _ = struct.unpack(\">H\", fp.read(2))  # dump padding bytes\n",
    "\n",
    "        (data_type,) = struct.unpack(\">c\", fp.read(1))\n",
    "        assert data_type == ALLOWED_TYPES[\"UNSIGNED_BYTE\"]\n",
    "\n",
    "        number_of_dimensions = ord(struct.unpack(\">c\", fp.read(1))[0])\n",
    "        assert number_of_dimensions == 1\n",
    "\n",
    "        (num_images,) = struct.unpack(\">I\", fp.read(4))\n",
    "        assert num_images == 60_000\n",
    "\n",
    "        raw = fp.read()\n",
    "        assert len(raw) == num_images\n",
    "\n",
    "    data = np.frombuffer(raw, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the metrics.py module.  This is has the responsibility of collecting metrics about the machine learning module, i.e. how well is it doing in predicting correct results.  Note that we're importing the Real number set from the Python numbers library, but we're using it interchangeably with float values in other variables.  This is a target for refactoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Real\n",
    "\n",
    "\n",
    "class Metric:\n",
    "    values: list[Real]\n",
    "    running_total: float\n",
    "    num_updates: float\n",
    "    average: float\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Metric(average={self.average:0.4f})\"\n",
    "\n",
    "    def update(self, value: Real, batch_size: int):\n",
    "        self.values.append(value)\n",
    "        self.running_total += value * batch_size\n",
    "        self.num_updates += batch_size\n",
    "        self.average = self.running_total / self.num_updates\n",
    "\n",
    "    def reset(self):\n",
    "        self.values: list[Real] = []\n",
    "        self.running_total: float = 0.0\n",
    "        self.num_updates: float = 0.0\n",
    "        self.average: float = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.py module creates our ML model using Pytorch.  Again, notice the structure of the forward() method.  We're using the same variable to store intermediate results.  This is a target for refactoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(in_features=28 * 28, out_features=32)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(in_features=32, out_features=10)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracking module is used to send the results to tensorboard.  Tensorboard is a web based application which displays metrics in a visual format. Note that the ExperimentTracker is an abstract base class, but not all methods in this class are abstract.  We'll see how we can replace the abstract base class with a new feature in Python called a *Protocol class*. \n",
    "Additionally, we'll discuss another new Python feature called a *Dataclass.*  Also note that we have a Stage class with three values  This might better be implemented as an Enum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from numbers import Real\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Stage:\n",
    "    TRAIN: str = 'train'\n",
    "    TEST: str = 'test'\n",
    "    VAL: str = 'val'\n",
    "\n",
    "\n",
    "class ExperimentTracker(ABC):\n",
    "    stage: str\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a batch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a epoch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int):\n",
    "        \"\"\"Implements logging a confusion matrix at epoch-level.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        \"\"\"Implements logging hyperparameters.\"\"\"\n",
    "\n",
    "    def add_batch_metrics(self, values: dict[str, Real], step: int):\n",
    "        for name, value in values.items():\n",
    "            self.add_batch_metric(name, value, step)\n",
    "\n",
    "    def add_epoch_metrics(self, values: dict[str, Real], step: int):\n",
    "        for name, value in values.items():\n",
    "            self.add_epoch_metric(name, value, step)\n",
    "\n",
    "\n",
    "class TensorboardExperiment(ExperimentTracker):\n",
    "\n",
    "    def __init__(self, log_dir: str, create=True):\n",
    "        self._validate_log_dir(log_dir, create=create)\n",
    "        self._writer = SummaryWriter(log_dir=log_dir)\n",
    "        plt.ioff()\n",
    "\n",
    "    def set_stage(self, stage: str):\n",
    "        self.stage = stage\n",
    "        return self\n",
    "\n",
    "    def flush(self):\n",
    "        self._writer.flush()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_log_dir(log_dir, create=True):\n",
    "        log_dir = Path(log_dir).resolve()\n",
    "        if log_dir.exists():\n",
    "            return\n",
    "        elif not log_dir.exists() and create:\n",
    "            log_dir.mkdir(parents=True)\n",
    "        else:\n",
    "            raise NotADirectoryError(f'log_dir {log_dir} does not exist.')\n",
    "\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "        tag = f'{self.stage}/batch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        tag = f'{self.stage}/epoch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_confusion_matrix(self, y_true: list[np.array], y_pred: list[np.array], step: int):\n",
    "        y_true, y_pred = self.collapse_batches(y_true, y_pred)\n",
    "        fig = self.create_confusion_matrix(y_true, y_pred, step)\n",
    "        tag = f'{self.stage}/epoch/confusion_matrix'\n",
    "        self._writer.add_figure(tag, fig, step)\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_batches(y_true: list[np.array], y_pred: list[np.array]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "    def create_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int) -> plt.Figure:\n",
    "        cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')\n",
    "        fig: plt.Figure = cm.figure_\n",
    "        ax: plt.Axes = cm.ax_\n",
    "        ax.set_title(f'{self.stage.title()} Epoch: {step}')\n",
    "        return fig\n",
    "\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        _metrics = self._validate_hparam_metric_keys(metrics)\n",
    "        self._writer.add_hparams(hparams, _metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_hparam_metric_keys(metrics):\n",
    "        _metrics = metrics.copy()\n",
    "        prefix = 'hparam/'\n",
    "        for name in _metrics.keys():\n",
    "            if not name.startswith(prefix):\n",
    "                _metrics[f'{prefix}{name}'] = _metrics[name]\n",
    "                del _metrics[name]\n",
    "        return _metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have a file called *utils.py*.  Which, as the name suggests contain a number of utility functions used by other parts of the application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def generate_tensorboard_experiment_directory(root: str, parents=True) -> str:\n",
    "    root = Path(root).resolve()\n",
    "    child = create_from_missing(root) if not root.exists() else create_from_existing(root)\n",
    "    child.mkdir(parents=parents)\n",
    "    return child.as_posix()\n",
    "\n",
    "\n",
    "def create_from_missing(root):\n",
    "    return root / '0'\n",
    "\n",
    "\n",
    "def create_from_existing(root):\n",
    "    children = [int(c.name) for c in root.glob('*') if (c.is_dir() and c.name.isnumeric())]\n",
    "    if is_first_experiment(children):\n",
    "        child = root / '0'\n",
    "    else:\n",
    "        child = root / increment_experiment_number(children)\n",
    "    return child\n",
    "\n",
    "\n",
    "def is_first_experiment(children: list[int]) -> bool:\n",
    "    return len(children) == 0\n",
    "\n",
    "\n",
    "def increment_experiment_number(children: list[int]) -> str:\n",
    "    return str(max(children) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Small Digression\n",
    "\n",
    "Here we'll digress from our topic to discuss two features of Python that we will use in our refactoring. \n",
    "The first features is the new Protocol class that was introduced in Python 3.8.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Classes\n",
    "The closest resemblance to a Protocol class in other languages might be the *Interface* features in Java.  Protocol classes are used as an implicit base class for other classes. \n",
    "\n",
    "Any class that has the same methods defined as the Protocol class are determined to be subclasses of the base class for any static typing analysis. \n",
    "\n",
    "Here's a simple exxample of a Protocol class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations manager\n",
      "Line worker\n"
     ]
    }
   ],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "class Person(Protocol):\n",
    "    \n",
    "    def returnRole(self) -> str:\n",
    "        pass\n",
    "    \n",
    "class Employee:\n",
    "    def __init__(self, role: str,salary: float):\n",
    "        self.role = role\n",
    "        self.salary = salary\n",
    "        \n",
    "    def returnRole(self) -> str:\n",
    "        return self.role\n",
    "    \n",
    "class Manager:\n",
    "    def __init__(self,role:str, salary: float):\n",
    "        self.role = role\n",
    "        self.salary = salary\n",
    "        \n",
    "    def returnRole(self) -> str:\n",
    "        return self.role\n",
    "    \n",
    "m = Manager('Operations manager',50000.00)\n",
    "e = Employee('Line worker',35000.00)\n",
    "\n",
    "print (m.returnRole())\n",
    "print (e.returnRole())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't have to explicitly define an inheritance structure in our sub classes.  Python uses *duck typing* to figure out the inheritance structure for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Classes ###\n",
    "The data class feature in Python is designed to make it easy to write classes where the main purpose of the class is to store data, rather than implement logic via methods.   Here's an example of how we would use a data class.\n",
    "\n",
    "Let's take an example of a class called Person. Before data classes we might easily implement a Person object as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "    numbeer_of_people: int = 0\n",
    "    def __init__(self,name: str, age: int, address:str):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.address = address\n",
    "        \n",
    "    def happyBirthday(self):\n",
    "        self.age += 1\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Name: {self.name}e Age:  {self.age} Address {self.address}\" \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a class like Person would require creating an __init__() method, as well as creating either a __str__() method, or a __repr__() method, or both.  \n",
    "\n",
    "Here's how we would do the same thing using a dataclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person(name='Braun', age=21, address='1234 Main Street')\n",
      "Person(name='Jon', age=19, address='1235 Main Street')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import ClassVar\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    \n",
    "    name: str\n",
    "    age:  int\n",
    "    address: str\n",
    "    number_of_people: ClassVar[int] = 0\n",
    "        \n",
    "    def __post__init__(self):\n",
    "        print (type(number_of_people))\n",
    "      #  Person.number_of_people[0] += 1\n",
    "        \n",
    "p1 = Person(\"Braun\", 21, \"1234 Main Street\")\n",
    "p2 = Person(\"Jon\", 19, \"1235 Main Street\")\n",
    "print (p1)\n",
    "print (p2)\n",
    "print (p1.number_of_people)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataclass handles much of the boilerplate that you would be required to write yourself.  No longer do you need to create an \\_\\_init\\_\\_() method, nor do you need to override the \\_\\_str\\_\\_() method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's refactor\n",
    "Lets start by looking at the ExperimentTracker class.  Specificlly this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Stage:\n",
    "    TRAIN: str = 'train'\n",
    "    TEST: str = 'test'\n",
    "    VAL: str = 'val'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a dataclass called Stage(The frozen=True option makes Stage immutable).  A better way to do this is to turn this into a enumeration (enum).   So, our new code looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto()\n",
    "\n",
    "class Stage(Enum):\n",
    "    \n",
    "    TRAIN = auto()\n",
    "    TEST = auto()\n",
    "    VAL = auto()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auto() method assigns an incrementing value to each element of the enum members. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our Tracking class.  There are a number of things we want to change.  We've already looked at changing the stage type to an enum, but also note that this is defined in the abstract base class.  It is usually never a great idea to define concrete variable types inside an ABC, so we'll move this out of the ABC and into the concrete class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from numbers import Real\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "from enum import Enum,  auto()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "class Stage(Enum):\n",
    "    TRAIN = auto()\n",
    "    TEST = auto()\n",
    "    VAL = auto()\n",
    "\n",
    "class ExperimentTracker(ABC):\n",
    "    \n",
    "    #Note here that stage is no longer a string, but a Stage enum, so we need to change its type. \n",
    "    # Additionally we want to remove the entire definition out of the Abstract class and into the\n",
    "    #concrete implementation. \n",
    "    #stage: str\n",
    "    \n",
    "\n",
    "    @abstractmethod\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a batch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a epoch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int):\n",
    "        \"\"\"Implements logging a confusion matrix at epoch-level.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        \"\"\"Implements logging hyperparameters.\"\"\"\n",
    "\n",
    "    def add_batch_metrics(self, values: dict[str, Real], step: int):\n",
    "        for name, value in values.items():\n",
    "            self.add_batch_metric(name, value, step)\n",
    "\n",
    "    def add_epoch_metrics(self, values: dict[str, Real], step: int):\n",
    "        for name, value in values.items():\n",
    "            self.add_epoch_metric(name, value, step)\n",
    "\n",
    "\n",
    "class TensorboardExperiment(ExperimentTracker):\n",
    "  \n",
    "# Move this from Abstract to concrete implementation. \n",
    "    stage: Stage\n",
    "\n",
    "    def __init__(self, log_dir: str, create=True):\n",
    "        self._validate_log_dir(log_dir, create=create)\n",
    "        self._writer = SummaryWriter(log_dir=log_dir)\n",
    "        plt.ioff()\n",
    "\n",
    "        #Change the stage type here as well. \n",
    "    def set_stage(self, stage: Stage):\n",
    "        self.stage = stage\n",
    "        return self\n",
    "\n",
    "    def flush(self):\n",
    "        self._writer.flush()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_log_dir(log_dir, create=True):\n",
    "        log_dir = Path(log_dir).resolve()\n",
    "        if log_dir.exists():\n",
    "            return\n",
    "        elif not log_dir.exists() and create:\n",
    "            log_dir.mkdir(parents=True)\n",
    "        else:\n",
    "            raise NotADirectoryError(f'log_dir {log_dir} does not exist.')\n",
    "      #Now that we've set the stage as an enum, we want to print out the stage name, not its value. \n",
    "      # We do this by chaining the name() method to the stage variable.\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "       # tag = f'{self.stage}/batch/{name}'\n",
    "        tag = f'{self.stage.name}/batch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "        \n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \n",
    "   \n",
    "      # Again, add the .name attribute. \n",
    "      #  tag = f'{self.stage}/epoch/{name}'\n",
    "        tag = f'{self.stage.name}/epoch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_confusion_matrix(self, y_true: list[np.array], y_pred: list[np.array], step: int):\n",
    "        y_true, y_pred = self.collapse_batches(y_true, y_pred)\n",
    "        fig = self.create_confusion_matrix(y_true, y_pred, step)\n",
    "        # Add the name attribute to the stage variable here as well. \n",
    "        # tag = f'{self.stage}/epoch/confusion_matrix'\n",
    "        tag = f'{self.stage.name}/epoch/confusion_matrix'\n",
    "\n",
    "        self._writer.add_figure(tag, fig, step)\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_batches(y_true: list[np.array], y_pred: list[np.array]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "    def create_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int) -> plt.Figure:\n",
    "        cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')\n",
    "        fig: plt.Figure = cm.figure_\n",
    "        ax: plt.Axes = cm.ax_\n",
    "        ax.set_title(f'{self.stage.title()} Epoch: {step}')\n",
    "        return fig\n",
    "\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        _metrics = self._validate_hparam_metric_keys(metrics)\n",
    "        self._writer.add_hparams(hparams, _metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_hparam_metric_keys(metrics):\n",
    "        _metrics = metrics.copy()\n",
    "        prefix = 'hparam/'\n",
    "        for name in _metrics.keys():\n",
    "            if not name.startswith(prefix):\n",
    "                _metrics[f'{prefix}{name}'] = _metrics[name]\n",
    "                del _metrics[name]\n",
    "        return _metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now pay attention to the ExperimentTracker abstract base class.  We note that this class consists of abstract and non-abstract methods.  Ideally, we'd like to move all concrete implementations out of the ABC and into the concrete class.  However, we notice that in this case, none of those non-abstract methods are actually being used. They really just call the abstract methods.   So, let's get rid of them altogether.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from numbers import Real\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "from enum import Enum,  auto()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class Stage(Enum):\n",
    "    TRAIN = auto()\n",
    "    TEST = auto()\n",
    "    VAL = auto()\n",
    "\n",
    "class ExperimentTracker(ABC):\n",
    "    \n",
    "    #Note here that stage is no longer a string, but a Stage enum, so we need to change its type. \n",
    "    # Additionally we want to remove the entire definition out of the Abstract class and into the\n",
    "    #concrete implementation. \n",
    "    #stage: str\n",
    "    \n",
    "\n",
    "    @abstractmethod\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a batch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a epoch-level metric.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_epoch_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int):\n",
    "        \"\"\"Implements logging a confusion matrix at epoch-level.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        \"\"\"Implements logging hyperparameters.\"\"\"\n",
    "\n",
    "## Removed the non-abstract methods from the ABC as they're never used. \n",
    "\n",
    "class TensorboardExperiment(ExperimentTracker):\n",
    "  \n",
    "# Move this from Abstract to concrete implementation. \n",
    "    stage: Stage\n",
    "\n",
    "    def __init__(self, log_dir: str, create=True):\n",
    "        self._validate_log_dir(log_dir, create=create)\n",
    "        self._writer = SummaryWriter(log_dir=log_dir)\n",
    "        plt.ioff()\n",
    "\n",
    "        #Change the stage type here as well. \n",
    "    def set_stage(self, stage: Stage):\n",
    "        self.stage = stage\n",
    "        return self\n",
    "\n",
    "    def flush(self):\n",
    "        self._writer.flush()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_log_dir(log_dir, create=True):\n",
    "        log_dir = Path(log_dir).resolve()\n",
    "        if log_dir.exists():\n",
    "            return\n",
    "        elif not log_dir.exists() and create:\n",
    "            log_dir.mkdir(parents=True)\n",
    "        else:\n",
    "            raise NotADirectoryError(f'log_dir {log_dir} does not exist.')\n",
    "      #Now that we've set the stage as an enum, we want to print out the stage name, not its value. \n",
    "      # We do this by chaining the name() method to the stage variable.\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "       # tag = f'{self.stage}/batch/{name}'\n",
    "        tag = f'{self.stage.name}/batch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "        \n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \n",
    "   \n",
    "      # Again, add the .name attribute. \n",
    "      #  tag = f'{self.stage}/epoch/{name}'\n",
    "        tag = f'{self.stage.name}/epoch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_confusion_matrix(self, y_true: list[np.array], y_pred: list[np.array], step: int):\n",
    "        y_true, y_pred = self.collapse_batches(y_true, y_pred)\n",
    "        fig = self.create_confusion_matrix(y_true, y_pred, step)\n",
    "        # Add the name attribute to the stage variable here as well. \n",
    "        # tag = f'{self.stage}/epoch/confusion_matrix'\n",
    "        tag = f'{self.stage.name}/epoch/confusion_matrix'\n",
    "\n",
    "        self._writer.add_figure(tag, fig, step)\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_batches(y_true: list[np.array], y_pred: list[np.array]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "    def create_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int) -> plt.Figure:\n",
    "        cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')\n",
    "        fig: plt.Figure = cm.figure_\n",
    "        ax: plt.Axes = cm.ax_\n",
    "        ax.set_title(f'{self.stage.title()} Epoch: {step}')\n",
    "        return fig\n",
    "\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        _metrics = self._validate_hparam_metric_keys(metrics)\n",
    "        self._writer.add_hparams(hparams, _metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_hparam_metric_keys(metrics):\n",
    "        _metrics = metrics.copy()\n",
    "        prefix = 'hparam/'\n",
    "        for name in _metrics.keys():\n",
    "            if not name.startswith(prefix):\n",
    "                _metrics[f'{prefix}{name}'] = _metrics[name]\n",
    "                del _metrics[name]\n",
    "        return _metrics\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are more issues around the Experiment Tracker. Let's look at our main.py file again. \n",
    "Here we see that we create an instance of Experiment as an TensorBoardExperiment object. The problem is that we can see that the main.py file calls both abstract *and* non-abstract methods from this object.  This means that we don't have a clean seperation of responsibility between the abstract ExperimentTracker class and the concrete TensorBoardExperiment class. In other words, there's absolutely no real benefit in making the ExperimentTracker an ABC.  Why does this matter? Because at this point, main.py cannot run with any generic type of ExperimentTracker because it is dependent on details from the concrete class.  This is an example  of a *dependency inversion* where a high level class is directly dependent on lower level class details.  This leads to fragile code, which is something we're trying to avoid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.dataset import get_train_dataloader, get_test_dataloader\n",
    "from src.metrics import Metric\n",
    "from src.models import LinearNet\n",
    "from src.tracking import TensorboardExperiment, Stage\n",
    "from src.utils import generate_tensorboard_experiment_directory\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    'EPOCHS': 20,\n",
    "    'LR': 5e-5,\n",
    "    'OPTIMIZER': 'Adam',\n",
    "    'BATCH_SIZE': 128\n",
    "}\n",
    "\n",
    "# Data\n",
    "train_loader = get_train_dataloader(batch_size=hparams.get('BATCH_SIZE'))\n",
    "test_loader = get_test_dataloader(batch_size=hparams.get('BATCH_SIZE'))\n",
    "\n",
    "# Model and Optimizer\n",
    "model = LinearNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams.get('LR'))\n",
    "\n",
    "# Objective (loss) function\n",
    "compute_loss = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "# Metric Containers\n",
    "train_accuracy = Metric()\n",
    "test_accuracy = Metric()\n",
    "y_true_batches = []\n",
    "y_pred_batches = []\n",
    "\n",
    "# Experiment Trackers\n",
    "log_dir = generate_tensorboard_experiment_directory(root='./runs')\n",
    "experiment = TensorboardExperiment(log_dir=log_dir)\n",
    "\n",
    "# Batch Counters\n",
    "test_batch = 0\n",
    "train_batch = 0\n",
    "\n",
    "for epoch in range(hparams.get('EPOCHS')):\n",
    "    # Testing Loop\n",
    "    for x_test, y_test in tqdm(test_loader, desc='Validation Batches', ncols=80):\n",
    "        test_batch += 1\n",
    "        test_batch_size = x_test.shape[0]\n",
    "        test_pred = model(x_test)\n",
    "        loss = compute_loss(test_pred, y_test)\n",
    "\n",
    "        # Compute Batch Validation Metrics\n",
    "        y_test_np = y_test.detach().numpy()\n",
    "        y_test_pred_np = np.argmax(test_pred.detach().numpy(), axis=1)\n",
    "        batch_test_accuracy = accuracy_score(y_test_np, y_test_pred_np)\n",
    "        test_accuracy.update(batch_test_accuracy, test_batch_size)\n",
    "        experiment.set_stage(Stage.VAL)\n",
    "        experiment.add_batch_metric('accuracy', batch_test_accuracy, test_batch)\n",
    "        y_true_batches += [y_test_np]\n",
    "        y_pred_batches += [y_test_pred_np]\n",
    "\n",
    "    # Training Loop\n",
    "    for x_train, y_train in tqdm(train_loader, desc='Train Batches', ncols=80):\n",
    "        train_batch += 1\n",
    "        train_batch_size = x_train.shape[0]\n",
    "        train_pred = model(x_train)\n",
    "        loss = compute_loss(train_pred, y_train)\n",
    "\n",
    "        # Compute Batch Training Metrics\n",
    "        y_train_np = y_train.detach().numpy()\n",
    "        y_train_pred_np = np.argmax(train_pred.detach().numpy(), axis=1)\n",
    "        batch_train_accuracy = accuracy_score(y_train_np, y_train_pred_np)\n",
    "        train_accuracy.update(batch_train_accuracy, train_batch_size)\n",
    "        experiment.set_stage(Stage.TRAIN)\n",
    "        experiment.add_batch_metric('accuracy', batch_train_accuracy, train_batch)\n",
    "\n",
    "        # Reverse-mode AutoDiff (backpropagation)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute Average Epoch Metrics\n",
    "    summary = ', '.join([\n",
    "        f\"[Epoch: {epoch + 1}/{hparams.get('EPOCHS')}]\",\n",
    "        f\"Test Accuracy: {test_accuracy.average: 0.4f}\",\n",
    "        f\"Train Accuracy: {train_accuracy.average: 0.4f}\",\n",
    "    ])\n",
    "    print('\\n' + summary + '\\n')\n",
    "\n",
    "    # Log Validation Epoch Metrics\n",
    "    experiment.set_stage(Stage.VAL)\n",
    "    experiment.add_epoch_metric('accuracy', test_accuracy.average, epoch)\n",
    "    experiment.add_epoch_confusion_matrix(y_true_batches, y_pred_batches, epoch)\n",
    "\n",
    "    # Log Validation Epoch Metrics\n",
    "    experiment.set_stage(Stage.TRAIN)\n",
    "    experiment.add_epoch_metric('accuracy', train_accuracy.average, epoch)\n",
    "\n",
    "    # Reset metrics\n",
    "    train_accuracy.reset()\n",
    "    test_accuracy.reset()\n",
    "\n",
    "experiment.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can fix this dependency inversion issue.  The first thing we'll do is ditch the abstract base class concept and replacce it with a protocol class.  We'll also move the concrete implementation of set_stage and flush into the protocol class so that it becomes part of the interface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from numbers import Real\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple\n",
    "from enum import Enum,  auto()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class Stage(Enum):\n",
    "    TRAIN = auto()\n",
    "    TEST = auto()\n",
    "    VAL = auto()\n",
    "    \n",
    "class ExperimentTracker(Protocol):\n",
    "    \n",
    "# Note that because this is now a protocol class, we can ditch the abstractmethod decorators on the methods.  This \n",
    "# cleans the code up a bit. \n",
    "    \n",
    "\n",
    "  #   @abstractmethod\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a batch-level metric.\"\"\"\n",
    "\n",
    " #   @abstractmethod\n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \"\"\"Implements logging a epoch-level metric.\"\"\"\n",
    "\n",
    " #   @abstractmethod\n",
    "    def add_epoch_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int):\n",
    "        \"\"\"Implements logging a confusion matrix at epoch-level.\"\"\"\n",
    "\n",
    " #   @abstractmethod\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        \"\"\"Implements logging hyperparameters.\"\"\"\n",
    "        \n",
    "    def set_stage(self, stage: Stage):\n",
    "        \"\"\" sets the stage \"\"\"\n",
    "    \n",
    "    def flush(self):\n",
    "       \"\"\" Flushes the experiment\"\"\"\n",
    "\n",
    "# TensorboardExperiment no longer needs to have an inheritance realtionship witih experiment tracker. \n",
    "#class TensorboardExperiment(ExperimentTracker):\n",
    "class TensorboardExperiment: \n",
    "    \n",
    "# Move this from Abstract to concrete implementation. \n",
    "    stage: Stage\n",
    "\n",
    "    def __init__(self, log_dir: str, create=True):\n",
    "        self._validate_log_dir(log_dir, create=create)\n",
    "        self._writer = SummaryWriter(log_dir=log_dir)\n",
    "        plt.ioff()\n",
    "\n",
    "        #Change the stage type here as well. \n",
    "    def set_stage(self, stage: Stage):\n",
    "        self.stage = stage\n",
    "        return self\n",
    "\n",
    "    def flush(self):\n",
    "        self._writer.flush()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_log_dir(log_dir, create=True):\n",
    "        log_dir = Path(log_dir).resolve()\n",
    "        if log_dir.exists():\n",
    "            return\n",
    "        elif not log_dir.exists() and create:\n",
    "            log_dir.mkdir(parents=True)\n",
    "        else:\n",
    "            raise NotADirectoryError(f'log_dir {log_dir} does not exist.')\n",
    "      #Now that we've set the stage as an enum, we want to print out the stage name, not its value. \n",
    "      # We do this by chaining the name() method to the stage variable.\n",
    "    def add_batch_metric(self, name: str, value: Real, step: int):\n",
    "       # tag = f'{self.stage}/batch/{name}'\n",
    "        tag = f'{self.stage.name}/batch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "        \n",
    "    def add_epoch_metric(self, name: str, value: Real, step: int):\n",
    "        \n",
    "   \n",
    "      # Again, add the .name attribute. \n",
    "      #  tag = f'{self.stage}/epoch/{name}'\n",
    "        tag = f'{self.stage.name}/epoch/{name}'\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_confusion_matrix(self, y_true: list[np.array], y_pred: list[np.array], step: int):\n",
    "        y_true, y_pred = self.collapse_batches(y_true, y_pred)\n",
    "        fig = self.create_confusion_matrix(y_true, y_pred, step)\n",
    "        # Add the name attribute to the stage variable here as well. \n",
    "        # tag = f'{self.stage}/epoch/confusion_matrix'\n",
    "        tag = f'{self.stage.name}/epoch/confusion_matrix'\n",
    "\n",
    "        self._writer.add_figure(tag, fig, step)\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_batches(y_true: list[np.array], y_pred: list[np.array]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "    def create_confusion_matrix(self, y_true: np.array, y_pred: np.array, step: int) -> plt.Figure:\n",
    "        cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap='Blues')\n",
    "        fig: plt.Figure = cm.figure_\n",
    "        ax: plt.Axes = cm.ax_\n",
    "        ax.set_title(f'{self.stage.title()} Epoch: {step}')\n",
    "        return fig\n",
    "\n",
    "    def add_hparams(self, hparams: dict[str, Union[str, Real]], metrics: dict[str, Real]):\n",
    "        _metrics = self._validate_hparam_metric_keys(metrics)\n",
    "        self._writer.add_hparams(hparams, _metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_hparam_metric_keys(metrics):\n",
    "        _metrics = metrics.copy()\n",
    "        prefix = 'hparam/'\n",
    "        for name in _metrics.keys():\n",
    "            if not name.startswith(prefix):\n",
    "                _metrics[f'{prefix}{name}'] = _metrics[name]\n",
    "                del _metrics[name]\n",
    "        return _metrics\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further refactoring can be done here.  There's no need to have the ExperimentTracker and TensorboardExperiment classes in teh same file.  A better organizational structure would be to move the TensorboardExperiment class into its own .py file. \n",
    "Here's what the new tracking.py file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "from pathlib import Path\n",
    "from typing import Protocol\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Stage(Enum):\n",
    "    TRAIN = auto()\n",
    "    TEST = auto()\n",
    "    VAL = auto()\n",
    "\n",
    "\n",
    "class ExperimentTracker(Protocol):\n",
    "    def set_stage(self, stage: Stage):\n",
    "        \"\"\"Sets the current stage of the experiment.\"\"\"\n",
    "\n",
    "    def add_batch_metric(self, name: str, value: float, step: int):\n",
    "        \"\"\"Implements logging a batch-level metric.\"\"\"\n",
    "\n",
    "    def add_epoch_metric(self, name: str, value: float, step: int):\n",
    "        \"\"\"Implements logging a epoch-level metric.\"\"\"\n",
    "\n",
    "    def add_epoch_confusion_matrix(\n",
    "        self, y_true: list[np.array], y_pred: list[np.array], step: int\n",
    "    ):\n",
    "        \"\"\"Implements logging a confusion matrix at epoch-level.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the new tensorboard.py file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from ds.tracking import Stage\n",
    "from ds.utils import create_experiment_log_dir\n",
    "\n",
    "#Don't forget to import Stage from the tracking module as we need it for the TensorboardExperiment implementation. \n",
    "from src.tracking import Stage\n",
    "\n",
    "\n",
    "class TensorboardExperiment:\n",
    "    def __init__(self, log_path: str, create: bool = True):\n",
    "\n",
    "        log_dir = create_experiment_log_dir(root=log_path)\n",
    "        self.stage = Stage.TRAIN\n",
    "        self._validate_log_dir(log_dir, create=create)\n",
    "        self._writer = SummaryWriter(log_dir=log_dir)\n",
    "        plt.ioff()\n",
    "\n",
    "    def set_stage(self, stage: Stage):\n",
    "        self.stage = stage\n",
    "\n",
    "    def flush(self):\n",
    "        self._writer.flush()\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate_log_dir(log_dir: str, create: bool = True):\n",
    "        log_path = Path(log_dir).resolve()\n",
    "        if log_path.exists():\n",
    "            return\n",
    "        elif not log_path.exists() and create:\n",
    "            log_path.mkdir(parents=True)\n",
    "        else:\n",
    "            raise NotADirectoryError(f\"log_dir {log_dir} does not exist.\")\n",
    "\n",
    "    def add_batch_metric(self, name: str, value: float, step: int):\n",
    "        tag = f\"{self.stage.name}/batch/{name}\"\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_metric(self, name: str, value: float, step: int):\n",
    "        tag = f\"{self.stage.name}/epoch/{name}\"\n",
    "        self._writer.add_scalar(tag, value, step)\n",
    "\n",
    "    def add_epoch_confusion_matrix(\n",
    "        self, y_true: list[np.array], y_pred: list[np.array], step: int\n",
    "    ):\n",
    "        y_true, y_pred = self.collapse_batches(y_true, y_pred)\n",
    "        fig = self.create_confusion_matrix(y_true, y_pred, step)\n",
    "        tag = f\"{self.stage.name}/epoch/confusion_matrix\"\n",
    "        self._writer.add_figure(tag, fig, step)\n",
    "\n",
    "    @staticmethod\n",
    "    def collapse_batches(\n",
    "        y_true: list[np.array], y_pred: list[np.array]\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        return np.concatenate(y_true), np.concatenate(y_pred)\n",
    "\n",
    "    def create_confusion_matrix(\n",
    "        self, y_true: list[np.array], y_pred: list[np.array], step: int\n",
    "    ) -> plt.Figure:\n",
    "        cm = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred)).plot(cmap=\"Blues\")\n",
    "        cm.ax_.set_title(f\"{self.stage.name} Epoch: {step}\")\n",
    "        return cm.figure_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that splitting these two files from the original tracking.py file makes both of the new files, easier to read and understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that the main.py file needs to change some import statements because we moved out the Experiment Tracker and the Tensorboard Experiment classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.dataset import get_train_dataloader, get_test_dataloader\n",
    "from src.metrics import Metric\n",
    "from src.models import LinearNet\n",
    "from src.tracking import Stage\n",
    "# We need a new import for the TensorboardExperiment class in our main.py file. \n",
    "from src.tensorboard import TensorboardExperiment\n",
    "from src.utils import generate_tensorboard_experiment_directory\n",
    "\n",
    "# ... Rest of main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit vs. implicit typing\n",
    "\n",
    "One thing you may have noticed is that we use both the instrisic float type for our numeric types as well as the Real type. Often times in the code we see these types being used interchangeably, i.e. implicit casting of types.  This is usually not a good coding practice.  It would be better if we were consistent with our numeric types. The code can get away with this because Python will implicitly cast Real types to floats.  But let's fix this problem so that we use explicit typing for all of our variables. \n",
    "\n",
    "In looking through the code, we see that we have the Real Number type used in a number of files, including metric.py and tracking.py.  Let's change those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We no longer need this import as we're not going to use the Real type any longer. \n",
    "# from numbers import Real\n",
    "\n",
    "\n",
    "class Metric:\n",
    "    # Change Real to float.\n",
    "    # values: list[Real]\n",
    "    values: list[float]\n",
    "    running_total: float\n",
    "    num_updates: float\n",
    "    average: float\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Metric(average={self.average:0.4f})\"\n",
    "\n",
    " # Change real param to float type.    \n",
    "    # def update(self, value: Real, batch_size: int):\n",
    "    def update (self, value: float, batch_size: int):\n",
    "        self.values.append(value)\n",
    "        self.running_total += value * batch_size\n",
    "        self.num_updates += batch_size\n",
    "        self.average = self.running_total / self.num_updates\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        #Change Real type to float\n",
    "        # self.values: list[Real] = []\n",
    "        self.values: list[float] = []\n",
    "        self.running_total: float = 0.0\n",
    "        self.num_updates: float = 0.0\n",
    "        self.average: float = 0.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
